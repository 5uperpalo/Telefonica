{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 Initialization \n",
    "## Section 1.1 Copy results of IMC2020_AntennaIMDAssignment to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -copyFromLocal datasets/Telefonica_Antenna/XG/telefonica_antenna_liverpool_imd_pd.csv QoE/Liverpool/\n",
    "hdfs dfs -copyFromLocal datasets/Telefonica_Antenna/XG/telefonica_antenna_london_imd_pd.csv QoE/London/\n",
    "hdfs dfs -copyFromLocal datasets/Telefonica_Antenna/XG/telefonica_antenna_birmingham_imd_pd.csv QoE/Birmingham/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2 PySpark and Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"SPARK_HOME\"] = '/usr/local/spark/spark-1.6.2-bin-hadoop2.6'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--master local[*] --deploy-mode client --packages com.databricks:spark-csv_2.11:1.3.0 pyspark-shell\"\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark import sql\n",
    "from pyspark.sql import HiveContext, Window, SQLContext\n",
    "from pyspark.sql.types import DoubleType, StructType, StructField, StringType\n",
    "from pyspark.sql.functions import col, lit, count, sum, avg, max, array\n",
    "\n",
    "print('starting')\n",
    "conf = SparkConf().setAppName('HomeDetection')\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# we need HiveContext to use Hive builtin functions:\n",
    "# hive builtin functions : https://support.treasuredata.com/hc/en-us/articles/360001457367-Hive-Built-in-Aggregate-Functions\n",
    "sqlContext = HiveContext(sc)\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2 Define datasets we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NightHours = ['/hour=00-04/part-*', '/hour=04-08/part-*']\n",
    "\n",
    "data_dirs = ['QoE/Liverpool/Liverpool_Jan_2020/',\n",
    "             'QoE/London/London_Jan_2020/',\n",
    "             'QoE/Birmingham/Birmingham_Jan_2020/']\n",
    "\n",
    "output_files = ['HomeAntenna_Liverpool_Jan_2020.csv',\n",
    "               'HomeAntenna_London_Jan_2020.csv',\n",
    "               'HomeAntenna_Birmingham_Jan_2020.csv']\n",
    "\n",
    "antenna_info_files = ['QoE/Liverpool/telefonica_antenna_liverpool_imd_pd.csv',\n",
    "                      'QoE/London/telefonica_antenna_london_imd_pd.csv',\n",
    "                      'QoE/Birmingham/telefonica_antenna_birmingham_imd_pd.csv']\n",
    "\n",
    "days = ['01', '02', '03']\n",
    "\n",
    "schema = StructType([StructField('device_id', StringType(), True),\n",
    "                     StructField('antenna_id', StringType(), True),\n",
    "                     StructField('time_spent', DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 Home antenna detection\n",
    "\n",
    "1.     iterate over days \n",
    "2.     split each row on \"tab\" \n",
    "3.     create data frames from two 4hour night intervals  \n",
    "3.1    dataframes have rows where each rows begins with device_id, gyration, 2 mistery values and [antena_id(lkey), time_spent]  pairs  \n",
    "3.2    each device_id has multiple rows \n",
    "4.     unite both time intervals, sum times for same antennas, keep the antenna with max time_spent \n",
    "5.     append dataframes from each day to final dataframe \n",
    "6.     add antenna coordinates to each antenna from antenna_coordinates dataset  \n",
    "7.     identify most common antenna_id for each ['device_id','geometry'] pair (save it to temp)\n",
    "8.     filter device_ids that connected to same coordinates at least 13x in the month -> final dataset\n",
    "9.     add most common antenna_id to each ['device_id', 'geometry'] pair in final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+\n",
      "|           device_id|            geometry| antenna_id|\n",
      "+--------------------+--------------------+-----------+\n",
      "|KIQXVF6+HxfnllhFR...|POINT (-196320.33...|    130-649|\n",
      "|QlQfCsgA9qPRiEj3M...|POINT (-196320.33...|    130-649|\n",
      "|E2gk2nlCd8X5RRZzo...|POINT (-196406.78...|    120-762|\n",
      "|FwK1+E7LGq3y0oVOj...|POINT (-196406.78...|    120-762|\n",
      "|qE1hJ+TbmbBq7p2Xu...|POINT (-196406.78...|    120-762|\n",
      "|LIKHcG2xA0wjQ8gfS...|POINT (-197214.56...|21218-11267|\n",
      "|WSi5v+Ywgxs34BoKt...|POINT (-197214.56...|   110-3716|\n",
      "|NdKSU96AdRJX2aNlQ...|POINT (-197525.12...|    120-429|\n",
      "|PdVD9cOkvhd10vsS2...|POINT (-197525.12...|    120-429|\n",
      "|IGLN9FJh+/dPYTUEU...|POINT (-197688.24...|    130-650|\n",
      "+--------------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data_dir,output_file,antenna_info_file in zip(data_dirs,output_files,antenna_info_files):\n",
    "    NightHours_00040008_final_df = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "    for day in days:\n",
    "        NightHours_0004 = sc.textFile(data_dir + day + NightHours[0]).map(lambda x: x.split('\\t'))\n",
    "        NightHours_0008 = sc.textFile(data_dir + day + NightHours[1]).map(lambda x: x.split('\\t'))\n",
    "        NightHours_0004_df = NightHours_0004.filter(lambda x: float(x[1]) <= 2000).flatMap(lambda x: [(x[0], x[i], x[i+1]) for i in range(5,len(x),2)])\\\n",
    "                                      .toDF(('device_id', 'antenna_id', 'time_spent'))\n",
    "        \n",
    "        NightHours_0008_df = NightHours_0008.filter(lambda x: float(x[1]) <= 2000).flatMap(lambda x: [(x[0], x[i], x[i+1]) for i in range(5,len(x),2)])\\\n",
    "                                      .toDF(('device_id', 'antenna_id', 'time_spent'))\n",
    "        \n",
    "        w = Window.partitionBy('device_id')\n",
    "        NightHours_00040008_df = NightHours_0004_df.unionAll(NightHours_0008_df)\n",
    "        NightHours_00040008_df = NightHours_00040008_df.groupby(['device_id', 'antenna_id']).agg(sum('time_spent').alias('time_spent'))\\\n",
    "                                      .withColumn('max_time_spent', max('time_spent').over(w))\\\n",
    "                                      .where(col('time_spent') == col('max_time_spent'))\\\n",
    "                                      .drop('max_time_spent')\n",
    "        \n",
    "        NightHours_00040008_final_df = NightHours_00040008_final_df.unionAll(NightHours_00040008_df)\n",
    "    \n",
    "    antenna_info = sqlContext.read.format('com.databricks.spark.csv').option('header', 'true').option('inferSchema', 'true').load(antenna_info_file)\n",
    "    antenna_info = antenna_info.drop('IMDDecil')\n",
    "    antenna_info = antenna_info.drop('generation')\n",
    "    antenna_info = antenna_info.drop('geometry_voronoi')\n",
    "    \n",
    "    NightHours_00040008_final_df = NightHours_00040008_final_df.join(antenna_info,[NightHours_00040008_final_df['antenna_id']==antenna_info['lkey']], 'left').drop('lkey')\n",
    "    \n",
    "    \n",
    "    # identification of most common antenna_id in for ['device_id','geometry'] pairs, based on solution from :\n",
    "    # https://stackoverflow.com/questions/45634725/pyspark-aggregate-on-the-most-frequent-value-in-a-column\n",
    "    temp = NightHours_00040008_final_df.groupby('device_id','geometry','antenna_id').count()\\\n",
    "                                       .withColumn('count_antenna_id', array('count', 'antenna_id'))\\\n",
    "                                       .groupby('device_id','geometry')\\\n",
    "                                       .agg(max('count_antenna_id').getItem(1).alias('antenna_id'))\n",
    "    temp = temp.withColumnRenamed('device_id', 'device_idd')\n",
    "    temp = temp.withColumnRenamed('geometry', 'geometryy')\n",
    "    \n",
    "    NightHours_00040008_final_df = NightHours_00040008_final_df.groupby(['device_id', 'geometry']).agg(count('geometry').alias('count_geometry'))\\\n",
    "                                                               .filter(col('count_geometry')>13)\n",
    "\n",
    "    NightHours_00040008_final_df = NightHours_00040008_final_df.groupby(['device_id', 'geometry'])\\\n",
    "                                                               .agg(max('count_geometry').alias('max_count_geometry'))\\\n",
    "                                                               .drop('max_count_geometry')\n",
    "        \n",
    "    NightHours_00040008_final_df = NightHours_00040008_final_df.join(temp, [NightHours_00040008_final_df['geometry']==temp['geometryy'], NightHours_00040008_final_df['device_id']==temp['device_idd']],'left')\n",
    "    NightHours_00040008_final_df = NightHours_00040008_final_df.drop('device_idd')\n",
    "    NightHours_00040008_final_df = NightHours_00040008_final_df.drop('geometryy')\n",
    "\n",
    "    # toPandas() for testing\n",
    "    #NightHours_00040008_final_df.toPandas().to_csv(output_file, index=False)\n",
    "    #NightHours_00040008_final_df.show(n=10)\n",
    "    \n",
    "    NightHours_00040008_final_df.coalesce(1).write.mode('append').format('com.databricks.spark.csv').option('header', 'true').save(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST OF \"MOST COMMON ANTENNA IDENTIFICATION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+\n",
      "|device_id|antenna_id|geometry|\n",
      "+---------+----------+--------+\n",
      "|        a|         y|      xx|\n",
      "|        a|         y|      xx|\n",
      "|        a|         x|      xx|\n",
      "|        a|         x|      xx|\n",
      "|        a|         x|      xx|\n",
      "+---------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_test = StructType([StructField('device_id', StringType(), True),\n",
    "                          StructField('antenna_id', StringType(), True),\n",
    "                          StructField('geometry', StringType(), True)])\n",
    "l = [['a','y','xx'],['a','y','xx'],['a','x','xx'],['a','x','xx'],['a','x','xx']]\n",
    "rdd = sc.parallelize(l)\n",
    "test = sqlContext.createDataFrame(rdd, schema_test)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------------------+\n",
      "|device_id|geometry|most_common_antenna_id|\n",
      "+---------+--------+----------------------+\n",
      "|        a|      xx|                     x|\n",
      "+---------+--------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregrated_table = test.groupby('device_id','geometry','antenna_id').count()\\\n",
    ".withColumn('count_antenna_id', array('count', 'antenna_id'))\\\n",
    ".groupby('device_id','geometry')\\\n",
    ".agg(max('count_antenna_id').getItem(1).alias('most_common_antenna_id'))\n",
    "aggregrated_table.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
